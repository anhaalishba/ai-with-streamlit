AI Code Reviewer
🧠 Overview

AI Code Reviewer is a multi-model AI-powered application built with LangChain and Streamlit.
It automatically reviews code, provides feedback, refactors it for better performance, and shares improvement tips — all in seconds!

This project demonstrates how to use three different AI models from three platforms:

🧩 Gemini (Google) → For merging final professional reports

🤗 Hugging Face (distilgpt2) → For generating smart coding tips

🦙 Open Source LLaMA (via Together/OpenAI endpoint) → For deep code review and refactoring

🚀 Features

✅ Multi-model integration (Gemini + Hugging Face + LLaMA)
✅ Parallel processing using RunnableParallel
✅ Automatic bug detection & code optimization suggestions
✅ Refactored version of the same code
✅ Professional, combined report generation
✅ Simple, interactive Streamlit UI

🏗️ Tech Stack

Python

LangChain

Streamlit

Google Gemini

Hugging Face Transformers

LLaMA Model (Open Source)

dotenv for environment management

⚙️ Installation Steps
1️⃣ Clone the Repository
git clone https://github.com/<your-username>/ai-code-reviewer.git
cd ai-code-reviewer

2️⃣ Create a Virtual Environment
python -m venv venv
venv\Scripts\activate    # (on Windows)
# or
source venv/bin/activate  # (on Mac/Linux)

3️⃣ Install Dependencies
pip install -r requirements.txt

4️⃣ Create a .env File

Inside your project folder, create a file named .env and add:

OPENAI_API_KEY=your_openai_or_together_api_key
OPENAI_BASE_URL=your_model_endpoint_url

5️⃣ Run the App
streamlit run app.py

🧩 Project Structure
📁 ai-code-reviewer/
│
├── app.py               # Main Streamlit app
├── requirements.txt     # Dependencies
├── README.md            # Documentation
└── .env                 # API keys (not shared publicly)

📄 Example Output

When you paste your code and click "Review Code", the app generates:

Review Section → Highlights bugs, logic issues, and improvements

Refactored Code → Cleaner, optimized version

Tips Section → 3 best practices generated by Hugging Face

Merged Report → A final formatted report from Gemini

🧠 Concepts Demonstrated

Multi-model orchestration with LangChain

Using RunnableParallel for parallel AI calls

Combining results with a merge chain

PromptTemplate usage per model

Streamlit UI integration

⚡ RunnableParallel – How It Works

RunnableParallel allows multiple models or chains to run simultaneously rather than sequentially.
In this project, it helps the app generate:

Review (using LLaMA model)

Refactor (using LLaMA model)

Tips (using Hugging Face model)

— all at the same time!

🔧 Code Example
parallel_chain = RunnableParallel({
    "review": review_template | code_review_model | parser,
    "refactor": refactor_template | code_review_model | parser,
    "tips": tips_template | suggestions_model | parser
})


This chain executes three different tasks concurrently, collects all results, and passes them to Gemini, which merges them into a single, professional Code Review Report.

🧩 Benefits

Faster execution (parallel processing)

Efficient use of multiple models

Demonstrates advanced LangChain pipeline design

✨ Future Improvements

Add syntax highlighting for reviewed code

Support multiple languages (Python, JavaScript, etc.)

Export reports as PDF

👩‍💻 Author

Developed by: Anha Alishba
